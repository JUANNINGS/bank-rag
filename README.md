# Bank RAG AI Agent ğŸ¦

**Melbourne First Bank AI-Powered Customer Service Assistant**

A production-ready Retrieval-Augmented Generation (RAG) system for intelligent Australian banking Q&A, built following enterprise best practices and PRD requirements.

> **ğŸ‡¦ğŸ‡º Australian Banking Content**: This system uses Melbourne First Bank as the example institution, with realistic Australian banking documents covering loans, credit cards, accounts, ATMs, overdraft protection, international transfers, and mobile banking.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [API Integration](#api-integration)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [Adding New Documents](#adding-new-documents)
- [Evaluation](#evaluation)
- [Requirements](#requirements)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Overview

The Bank RAG system provides intelligent, context-aware answers to banking questions using:

- **Hybrid Retrieval**: Combines BM25 (keyword) + FAISS (semantic) for optimal results
- **Azure OpenAI**: GPT-4.1 for generation, ada-002 for embeddings
- **Citation Mechanism**: Tracks which documents were used to answer questions
- **Refusal Mechanism**: Declines to answer when confidence is low
- **Production-Ready**: Modular Python architecture ready for API integration

### Key Metrics (from PRD)
- âœ… Response time: < 3 seconds (target)
- âœ… Retrieval Precision: â‰¥ 90% (target)
- âœ… Generation Accuracy: â‰¥ 85% (target)

---

## âœ¨ Features

### Core Capabilities
- **Multi-format Support**: PDF, DOCX, HTML, TXT documents
- **Intelligent Chunking**: Optimized text splitting with overlap
- **Hybrid Search**: Best of keyword and semantic search
- **Source Attribution**: Every answer cites its sources
- **Confidence Scoring**: Know when the system is uncertain
- **Evaluation Framework**: Built-in metrics (Hit Rate, MRR, nDCG, Precision)

### Australian Banking Content
- 7 comprehensive Melbourne First Bank documents (44,000+ words):
  - Personal loans policy
  - Credit card FAQ
  - Account types (transaction, savings, term deposits)
  - ATM & branch locations (Victoria-wide)
  - International money transfers (PayID, BPAY, Osko)
  - Mobile banking guide
  - Overdraft protection guide

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Query     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Hybrid Retriever          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   BM25   â”‚  Vector  â”‚    â”‚
â”‚  â”‚ (Keyword)â”‚(Semantic)â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â”‚
â”‚       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚
â”‚             â”‚               â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚      â”‚   Reranker   â”‚       â”‚
â”‚      â”‚  (Optional)  â”‚       â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Context   â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Azure GPT  â”‚
       â”‚  Generator  â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response + Citations        â”‚
â”‚  + Confidence Score          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack
- **LLM**: Azure OpenAI GPT-4.1
- **Embeddings**: Azure OpenAI ada-002
- **Vector Store**: FAISS (Facebook AI Similarity Search)
- **Keyword Search**: BM25
- **Framework**: LangChain
- **Language**: Python 3.8+

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8 or higher
- Azure OpenAI API key and endpoint
- 2GB+ RAM (for vector store)

### Installation

```bash
# 1. Navigate to project directory
cd bank_RAG

# 2. Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure credentials
# Create .env file with your Azure OpenAI credentials
# (See .env file in the project or config.py for required variables)
```

### First Run

```bash
# Interactive mode (recommended for testing)
python main.py interactive

# Or batch mode
python main.py batch

# Or evaluation mode
python main.py eval
```

---

## ğŸ’» Usage

### 1. Interactive Mode

```bash
python main.py interactive
```

Ask questions naturally:
```
ğŸ’¬ Your question: What are the fees for wire transfers?

ğŸ¤– Answer:
For TechBank customers, wire transfer fees vary by account type:
- Basic/Preferred Checking: $25 domestic outgoing, $45 international
- Premium Checking: FREE for all wire transfers
...

ğŸ“Š Confidence: 95%
â±ï¸  Response time: 1.23s
ğŸ“š Sources:
  1. wire_transfer_guide.txt
```

### 2. Python API Usage

```python
from main import BankRAGSystem

# Initialize system
rag_system = BankRAGSystem()

# Ask a question
response = rag_system.query("How do I apply for a loan?")

# Access response
print(response.answer)           # The generated answer
print(response.confidence)       # Confidence score (0-1)
print(response.sources)          # List of source documents
print(response.is_refusal)       # Whether system refused to answer
print(response.response_time)    # Time taken in seconds

# Get as dictionary (JSON-serializable)
response_dict = response.to_dict()
```

### 3. Batch Processing

```python
from main import BankRAGSystem

system = BankRAGSystem()

questions = [
    "What is the interest rate on savings?",
    "How do I use mobile deposit?",
    "What are ATM fees?"
]

responses = system.batch_query(questions)

for q, r in zip(questions, responses):
    print(f"Q: {q}")
    print(f"A: {r.answer[:100]}...")
    print()
```

---

## ğŸ”Œ API Integration

### FastAPI Example

```python
# api.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from main import BankRAGSystem

app = FastAPI(title="Bank RAG API")
rag_system = BankRAGSystem()

class QuestionRequest(BaseModel):
    question: str
    include_sources: bool = True

@app.post("/api/v1/query")
async def query_endpoint(request: QuestionRequest):
    """Query the RAG system"""
    try:
        response = rag_system.query(
            request.question,
            include_sources=request.include_sources
        )
        return response.to_dict()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "service": "bank-rag"}

# Run: uvicorn api:app --reload --port 8000
```

### Response Format

```json
{
  "answer": "To apply for a personal loan at TechBank...",
  "confidence": 0.92,
  "is_refusal": false,
  "response_time": 1.45,
  "sources": [
    {
      "source": "loan_policy.txt",
      "chunk_id": "chunk_42",
      "excerpt": "Personal Loan Application Process..."
    }
  ],
  "metadata": {
    "num_retrieved_docs": 5,
    "question_length": 32,
    "answer_length": 456
  }
}
```

### Frontend Integration Example

```javascript
// React/JavaScript example
async function askBankQuestion(question) {
  const response = await fetch('http://localhost:8000/api/v1/query', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ 
      question: question,
      include_sources: true 
    })
  });
  
  const data = await response.json();
  
  return {
    answer: data.answer,
    confidence: data.confidence,
    sources: data.sources,
    responseTime: data.response_time
  };
}

// Usage
const result = await askBankQuestion("What are your credit card options?");
console.log(result.answer);
```

---

## ğŸ“ Project Structure

```
bank_RAG/
â”œâ”€â”€ config.py                    # Configuration (Azure OpenAI, RAG params)
â”œâ”€â”€ document_loader.py           # Load PDF/DOCX/HTML/TXT files
â”œâ”€â”€ chunking.py                  # Text splitting and preprocessing
â”œâ”€â”€ embeddings.py                # Azure OpenAI embeddings generation
â”œâ”€â”€ retriever.py                 # Hybrid retrieval (BM25 + Vector)
â”œâ”€â”€ rag_pipeline.py              # Main RAG logic + citation + refusal
â”œâ”€â”€ evaluation.py                # Evaluation metrics (Hit Rate, MRR, nDCG)
â”œâ”€â”€ main.py                      # Entry point and demos
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â”‚
â”œâ”€â”€ documents/                   # Banking documents (knowledge base)
â”‚   â”œâ”€â”€ loan_policy.txt
â”‚   â”œâ”€â”€ credit_card_faq.txt
â”‚   â”œâ”€â”€ account_types.txt
â”‚   â”œâ”€â”€ atm_locations.txt
â”‚   â”œâ”€â”€ wire_transfer_guide.txt
â”‚   â””â”€â”€ mobile_banking_guide.txt
â”‚
â”œâ”€â”€ data/                        # Generated data
â”‚   â””â”€â”€ vector_store/            # FAISS index (auto-generated)
â”‚       â”œâ”€â”€ index.faiss
â”‚       â””â”€â”€ index.pkl
â”‚
â””â”€â”€ tests/                       # Test files and results
    â””â”€â”€ evaluation_results.json  # Evaluation metrics output
```

---

## âš™ï¸ Configuration

### .env file (credentials)

Create a `.env` file in the project root with your Azure OpenAI credentials:

```bash
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_GPT_DEPLOYMENT=gpt-4
AZURE_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
```

### config.py (system parameters)

```python
# RAG Parameters
chunk_size = 1000              # Characters per chunk
chunk_overlap = 200            # Overlap between chunks
top_k = 5                      # Number of chunks to retrieve
refusal_threshold = 0.3        # Minimum confidence to answer
```

### Optional: Cohere Reranking

```bash
# Add to .env file
COHERE_API_KEY=your-cohere-key
```

---

## ğŸ“„ Adding New Documents

### Supported Formats
- `.txt` - Plain text
- `.pdf` - PDF documents
- `.docx` - Microsoft Word
- `.html` - HTML files

### Steps

1. **Add document to documents/ folder**
   ```bash
   cp /path/to/new_policy.pdf documents/
   ```

2. **Rebuild vector store**
   ```python
   # Documents are automatically loaded on next run
   python main.py interactive
   ```
   
   Or programmatically:
   ```python
   from document_loader import load_banking_documents
   from chunking import chunk_banking_documents
   from embeddings import create_embeddings_generator
   from retriever import create_vector_retriever
   
   # Reload documents
   documents = load_banking_documents("./documents")
   chunks = chunk_banking_documents(documents)
   embeddings = create_embeddings_generator()
   
   # Rebuild vector store
   retriever, vector_store = create_vector_retriever(
       chunks,
       embeddings.get_embeddings_model(),
       save_path="./data/vector_store"
   )
   ```

3. **Update evaluation** (optional)
   Add test queries in `evaluation.py`:
   ```python
   {
       'query': 'New question about the new document?',
       'expected_sources': ['new_policy.pdf']
   }
   ```

---

## ğŸ“Š Evaluation

### Run Evaluation

```bash
python main.py eval
```

### Metrics Explained

| Metric | Description | Target | Example |
|--------|-------------|--------|---------|
| **Hit Rate** | Did we find any relevant document? | â‰¥ 85% | Found loan_policy.txt for "How to apply for loan?" |
| **MRR** | Mean Reciprocal Rank - How high was first relevant doc? | Higher is better | Relevant doc was 2nd â†’ MRR = 0.5 |
| **nDCG** | Ranking quality considering all docs | 0-1 (higher better) | All relevant docs in top 3 â†’ high nDCG |
| **Precision@k** | % of retrieved docs that are relevant | â‰¥ 90% | 4 out of 5 retrieved docs relevant â†’ 80% |

### Sample Output

```
==============================================================
EVALUATION RESULTS
==============================================================
Number of queries: 10
Hit Rate:         90.00% (found relevant doc)
MRR:              0.7500 (avg reciprocal rank)
nDCG:             0.8234 (ranking quality)
Precision:        92.00% (relevant docs ratio)
==============================================================

PRD REQUIREMENTS CHECK
==============================================================
Target: Retrieval Precision â‰¥ 90%
Actual: 92.00%
Status: âœ“ PASS
```

---

## ğŸ“¦ Requirements

### Python Packages (Latest Versions)

```
langchain >= 0.3.0
langchain-openai >= 0.2.0
langchain-community >= 0.3.0
openai >= 1.50.0
faiss-cpu >= 1.8.0
rank-bm25 >= 0.2.2
pypdf >= 5.0.0
python-docx >= 1.1.2
numpy >= 1.26.0
pandas >= 2.2.0
pydantic >= 2.9.0
```

See `requirements.txt` for complete list.

**Note**: The project uses the latest stable versions of all libraries (as of October 2024) for best performance, security, and Azure OpenAI compatibility.

### System Requirements

- Python 3.8+
- 2GB+ RAM
- Internet connection (for Azure OpenAI API)
- ~500MB disk space (for dependencies and vector store)

---

## ğŸ”§ Troubleshooting

### Issue: "No module named 'langchain'"

**Solution:**
```bash
pip install -r requirements.txt
```

### Issue: "Azure OpenAI API authentication failed"

**Solution:**
1. Check `config.py` has correct API key
2. Verify endpoint URL is correct
3. Ensure deployments exist in Azure portal
```python
# config.py
api_key = "your-actual-key-here"  # Get from Azure portal
endpoint = "https://newaimchatgpt.openai.azure.com/"
```

### Issue: "FAISS index not found"

**Solution:**
Vector store is auto-created on first run. Just run:
```bash
python main.py interactive
```

### Issue: "Response time > 3 seconds"

**Possible causes:**
- First query (cold start): Normal, subsequent queries are faster
- Large document corpus: Consider reducing chunk size
- Network latency: Check Azure OpenAI endpoint latency

**Optimization:**
```python
# config.py
chunk_size = 800  # Reduce from 1000
top_k = 3         # Reduce from 5
```

### Issue: "Low confidence scores"

**Solutions:**
1. Add more relevant documents to knowledge base
2. Improve document quality and formatting
3. Adjust confidence threshold:
```python
# config.py
refusal_threshold = 0.2  # Lower threshold (was 0.3)
```

### Issue: "Module not found" errors

**Solution:**
Ensure virtual environment is activated:
```bash
# Linux/Mac
source venv/bin/activate

# Windows
venv\Scripts\activate

# Then reinstall
pip install -r requirements.txt
```

---

## ğŸ§ª Testing

### Unit Tests (Optional)

```bash
# Run tests
pytest

# With coverage
pytest --cov=. --cov-report=html
```

### Manual Testing Checklist

- [ ] System initializes without errors
- [ ] Can query simple questions
- [ ] Sources are cited correctly
- [ ] Confidence scores are reasonable
- [ ] Refusal mechanism works (try unrelated questions)
- [ ] Response time < 3 seconds
- [ ] Vector store persists between runs

---

## ğŸ“ˆ Performance Monitoring

### Log Analysis

Logs show timing for each step:
```
INFO - Retrieved 5 documents in 0.23s
INFO - Generated answer in 1.02s
INFO - Response generated in 1.45 seconds
```

### Metrics to Track

- **Response Time**: Target < 3 seconds
- **Confidence**: Average should be > 0.7
- **Refusal Rate**: Should be < 15%
- **Hit Rate**: Should be > 85%

---

## ğŸ” Security Notes

### API Key Management

âš ï¸ **IMPORTANT**: Never commit API keys to version control!

```bash
# Add to .gitignore
echo "config.py" >> .gitignore
echo ".env" >> .gitignore
```

Use environment variables in production:
```python
import os
api_key = os.getenv("AZURE_OPENAI_API_KEY")
```

---

## ğŸ¤ For Full-Stack Team

### Integration Points

1. **REST API**: Use FastAPI example above
2. **Direct Python**: Import `BankRAGSystem` class
3. **Microservice**: Deploy as separate service

### Key Classes

- `BankRAGSystem`: Main interface (use this!)
- `RAGResponse`: Structured response object
- `BankRAGPipeline`: Core RAG logic

### Response Schema

```python
@dataclass
class RAGResponse:
    answer: str              # Generated answer
    sources: List[Dict]      # Source citations
    confidence: float        # 0-1 score
    is_refusal: bool         # Whether declined to answer
    response_time: float     # Seconds taken
    metadata: Dict           # Additional info
```

---

## ğŸ“ Support

For questions or issues:
- **Data Engineering Team**: Check code comments and docstrings
- **Azure OpenAI**: See Azure portal documentation
- **LangChain**: https://python.langchain.com/docs/

---

## ğŸ“ License

Internal TechBank project. Proprietary and confidential.

---

## ğŸ¯ Next Steps

1. âœ… Test the system with sample queries
2. âœ… Review evaluation metrics
3. ğŸ”„ Add more banking documents as needed
4. ğŸ”„ Integrate with your API/frontend
5. ğŸ”„ Monitor performance in production
6. ğŸ”„ Fine-tune parameters based on user feedback

---

---

## ğŸ“ Project Notes

### Australian Banking Content
This RAG system is configured for **Melbourne First Bank** with Australian banking terminology:
- Currency: AUD (not USD)
- Payment systems: PayID, BPAY, Osko (not Zelle, ACH)
- Regulations: AUSTRAC, APRA (not FDIC, FINRA)
- Locations: Melbourne, Geelong, Ballarat (Victoria)
- Phone: 13 MELB (13 6352) - Australian format

### Latest Libraries
All packages use the latest stable versions (October 2024):
- LangChain 0.3.x for improved performance
- OpenAI 1.50+ for better Azure support
- No deprecation warnings
- Production-ready and future-proof

### Code Quality
- âœ… 0 linter errors
- âœ… Clean imports (langchain_community)
- âœ… Type hints throughout
- âœ… Comprehensive documentation
- âœ… Modular architecture

---

**Built with â¤ï¸ by the Data Engineering Team for Melbourne Projects**
